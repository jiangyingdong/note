# 人工特征识别

1）使用 Python opencv库以及numpy库

```
import cv2
import numpy as np
```

2）Canny算法进行边缘提取

```python
def Opencv_canny_edge_extraction(img):
    #img: 原图像
    gaus = cv2.GaussianBlur(img, (3, 3), 0) #高斯模糊
    gray = cv2.cvtColor(gaus,cv2.COLOR_BGR2GRAY) #灰度化
    gradx = cv2.Sobel(gray, cv2.CV_16SC1, 1, 0)
    grady = cv2.Sobel(gray, cv2.CV_16SC1, 0, 1)
    edge_out = cv2.Canny(gradx, grady, 50, 150)  # 黑白的边缘 高低阈值比值为2:1或3:1最佳(50:150 = 1:3)
    dst = cv2.bitwise_and(img, img,mask=edge_out)  # 彩色的边缘
    return edge_out,dst
```

3）将提取的边缘图像划分为m×n个区域，作为污染物中心候选区域

4）遍历每个区域，判断该区域是否满足在上下左右区域群内像素值和是最大的条件，若满足则记为疑似污染物区域

5）设定阈值筛选像素和过低的疑似区域

6）遍历每个疑似区域，对该区域进行扩充，直到覆盖整个污染物；

```python
img = cv2.imread(r'C:\Users\jyd\Pictures\Camera Roll\u=1520823874,3159901746&fm=15&gp=0.png') #获取图像
img_01, img_BGR = Opencv_canny_edge_extraction(img) #进行边缘提取
img_GRAY = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2GRAY) #从BGR图像获取灰度图
img_h, img_w = img_GRAY.shape #图像的宽高
r = 30 #候选区域的半径
m = img_w//(r+1)-1 #x轴候选区域的个数
n = img_h//(r+1)-1 #y轴候选区域的个数
x_ = (img_w%(r+1))//2 #确定第一个候选区域的左上坐标
y_ = (img_h%(r+1))//2
sum_list = list() #保存每个候选区域像素值和的列表
for i in range(n):
    y = y_ + i*(r+1)
    for j in range(m):
        x = x_ + j*(r+1)
        sum_list.append(np.sum(img_GRAY[y:y+(2*r+1), x:x+(2*r+1)])) #求每个候选区域的像素值和
sum_arr = np.array(sum_list).reshape(n,m)
#print(sum_arr)
sum_limit = 20000 #像素值和的筛选阈值
D_list = list() #存放疑似目标的中心点坐标
for i in range(n): #筛选极大值区域
    for j in range(m):
        right = left = down = up = True #极值的标记变量
        if sum_arr[i,j]>sum_limit:
            if j+1<m:
                if sum_arr[i,j]<sum_arr[i,j+1]:
                    right = False
            if i+1<n:
                if sum_arr[i,j]<sum_arr[i+1,j]:
                    down = False
            if j-1>=0:
                if sum_arr[i,j]<sum_arr[i,j-1]:
                    left = False
            if i-1>=0:
                if sum_arr[i,j]<sum_arr[i-1,j]:
                    up = False
            if right and down and left and up: #若确定该区域是疑似目标区则计算中心点坐标
                if j!=0: x = x_+(j*(r+1))+r
                else: x = x_ + r
                if i!=0: y = y_+(i*(r+1))+r
                else: y = y_ + r
                D_list.append((x,y,r))

step = 1 #补充的步长
for i in D_list: #依次对疑似目标区域进行补充
    ri = do = le = up = i[2] #疑似目标区域中心点到四周的距离
    rect = [0,0,0,0]
    rect[0] = i[0]-i[2] #疑似目标区域左上后下的坐标
    rect[1] = i[1]-i[2]
    rect[2] = i[0]+i[2]
    rect[3] = i[1]+i[2]    
    while 1:
        l = [0,0]
        if rect[2]+step<img_w: #补充时不越界则判断下一步是否纳入区域
            c = np.sum(img_GRAY[rect[1]:rect[3]+1,rect[2]+1:rect[2]+1+step])
            if l[0] < c: l = [c,2]
        if rect[3]+step<img_h: #补充时不越界则判断下一步是否纳入区域
            c = np.sum(img_GRAY[rect[3]+1:rect[3]+step+1,rect[0]:rect[2]+1])
            if l[0] < c: l = [c,3]
        if rect[2]-step>=0: #补充时不越界则判断下一步是否纳入区域
            c = np.sum(img_GRAY[rect[1]:rect[3]+1,rect[0]-step:rect[0]])
            if l[0] < c: l = [c,0]
        if rect[3]-step>=0: #补充时不越界则判断下一步是否纳入区域
            c = np.sum(img_GRAY[rect[1]-step:rect[1],rect[0]:rect[2]+1])
            if l[0] < c: l = [c,1]
        if l[0] > 100 : 
            if l[1] >= 2: rect[l[1]] += step
            else: rect[l[1]] -= step
        else: break
    cv2.rectangle(img,(rect[0],rect[1]),(rect[2],rect[3]),(0,0,255),1) #标记原图像 img
    cv2.rectangle(img_GRAY,(rect[0],rect[1]),(rect[2],rect[3]),(255,255,255),1) #标记边缘图像 img_GRAY
```



# AlexNet网络提取特征识别

## 工具文件 Function_Diy.py

```python
'''
Created on 2020年7月4日

@author: jyd
'''
import numpy as np
import random
import cv2
import os
import tensorflow as tf
import time


def Alter_image_size(image, target_size):
    '''
    @warning: 改变图像尺寸
    
    @param image: 需要改变尺寸的图像
    @param target_size: 目标尺寸大小，是个列表
    
    @return: image_paded: 新图片，尺寸是target_size
    '''    
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)#shape=[?,?,3]

    ih, iw    = target_size #将image图片尺寸改变至target_size
    h,  w, _  = image.shape

    scale = min(iw/w, ih/h)
    nw, nh  = int(scale * w), int(scale * h)
    image_resized = cv2.resize(image, (nw, nh)) #改变image图片的尺寸，image_resized 是新图片

    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)
    dw, dh = (iw - nw) // 2, (ih-nh) // 2
    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized
    image_paded = image_paded / 255.
    
    return image_paded
    
def folder_to_dict(folder_path):
    #folder_path: 要遍历的文件夹的路径
    #返回一个字典
    dict_path = dict()
    for path, list_folder, list_file in os.walk(folder_path):
        dict_path['path'] = path
        for folder_name in list_folder:
            dict_path[folder_name] = folder_to_dict(path+'\\'+folder_name)
        dict_path['list_file'] = list()
        for list_file_name in list_file:            
            dict_path['list_file'].append(path+'\\'+list_file_name)
        break        
    return dict_path

def Build_datasets(dict_data_folder, target_image_size=[224, 224]):
    #dict_data_folder: 利用folder_to_dict(folder_path)函数得到的字典，该文件目录只有3层
    #target_image_size: 网络的输入图片尺寸
    #返回(train_images, train_lables, test_images, test_lables)元组，都是list(array())格式
    dict_data = dict()
    for k1,v1 in dict_data_folder.items():
        if (k1 != 'list_file') and (k1 != 'path'):
            dict_data[k1] = list()    #用于存放训练或测试数据的list
            count_class = len(v1) - 2 #类别的数量，v1除了类别字段还有path和list_file字段，所以-2
            to_class = 0 #指向第一个类别
            for k2,v2 in v1.items(): #遍历每个类别
                if k2 != 'list_file' and k2 != 'path':
                    lable_array = np.zeros((count_class,)) #类别标签
                    to_class = to_class + 1 #指向下一个类别
                    for x in v2['list_file']: #遍历图片
                        lable_array[to_class-1]=1 #把当前类别置1                        
                        dict_data[k1].append([x,lable_array]) #向数据集list中添加[图片路径, 对应的标签]
            np.random.shuffle(dict_data[k1]) #乱序
    #print(dict_data)#{key:list(list(str,array)), key:list(list(str,array))}格式的字典，str是图片路径，array是对应的标签
    train_images = list()
    train_lables = list()
    test_images = list()
    test_lables = list()
    for k,v in dict_data.items():
        if k.lower().find('train') != -1:
            for x in v:
                train_images.append(Alter_image_size(cv2.imread(x[0]), target_image_size)/255)#读取图片并归一化和改变尺寸,Alter_image_size(image, target_size)函数用来改变图片尺寸
                train_lables.append(x[1])
        if k.lower().find('test') != -1:
            for x in v:
                test_images.append(Alter_image_size(cv2.imread(x[0]), target_image_size)/255)#读取图片并归一化和改变尺寸
                test_lables.append(x[1])
    return(train_images, train_lables, test_images, test_lables)
def LoadPB(pb_file,return_elements):
        #warning: 该函数用于读取pb文件，返回网络图和关键张量            
        #param pb_file: pb文件路径
        #param return_elements: 这是一个列表，输入输出张量的名称            
        #return: graph: 一个图，利用session去run输出张量时，需要这个
        #return: return_elements: 这是一个列表，输入输出张量           
        
        with tf.gfile.FastGFile(pb_file, 'rb') as f:    #读取pb文件
            frozen_graph_def = tf.GraphDef()            #获取默认的图
            frozen_graph_def.ParseFromString(f.read())  #利用默认图加载pb文件内数据
        
        graph = tf.Graph()#创建一个新图
        with graph.as_default():    #改变graph为默认图
            #获取pb文件中固定的tensor
            return_elements = tf.import_graph_def(frozen_graph_def,return_elements=return_elements)
        
        return graph,return_elements
def Predict_by_PB(pb_file_path, image_path_name):
    #利用pb模型文件对给定的照片进行预测
    #image_path_name: 要预测的图片的文件路径   
    
    pb_gragh, pb_list_tensor = LoadPB(pb_file_path,['input_data:0', 'keep_prob:0', 'output_data:0']) #加载模型,获取计算图与关键张量
    image = Alter_image_size(cv2.imread(image_path_name), [224, 224])/255 #改变图片的大小,使其符合网络的要求
    image = image.reshape(1,224,224,3)
    with tf.Session(graph=pb_gragh) as sess: #给session添加默认图
        print(sess.run(pb_list_tensor[2], feed_dict = {pb_list_tensor[0]: image, pb_list_tensor[1]:0.5})) #预测
        
        
def camera(iamge_save_path='./'):
    #iamge_save_path: 截取的图片保存的路径，图片名程序自定义
    winName = "img"  #窗口名
    cv2.namedWindow(winName,2)    #创建可改变窗口
    cap = cv2.VideoCapture(0) #调用笔记本内置摄像头，所以参数为0，如果有其他的摄像头可以调整参数为1，2
    while cap.isOpened():
        success,img = cap.read()#从摄像头读取图片
        if success:
            cv2.imshow(winName,img)   #打开图片
        k = cv2.waitKey(1) #保持画面持续
        if k == 27: #按Esc键退出
            cv2.destroyAllWindows()
            cap.release()#关闭摄像头
        elif k == ord('s'): #按s键截图并保存
            image_name = 'image'+str(int(time.time()))+'.jpg'
            cv2.imwrite(os.path.join(iamge_save_path,image_name),img)
            print('保存图片:',image_name,'至:',iamge_save_path)

import matplotlib.pyplot as plt
def show_data1(Title='Title', Xaxis='Xaxis', Yaxis='Yaxis'):
    plt.title(Title)  #标题
    plt.xlabel(Xaxis) #X轴名称
    plt.ylabel(Yaxis) #Y轴名称
    plt.ion()
    while 1:
        data = yield
        if(data=='over'):
            break
        plt.clf() #清除画布
        plt.plot(data[0],data[1], label = 'loss')
        plt.plot(data[0],data[2], label = 'avg')
        plt.legend()
        plt.draw() #在画布上画出图像
        plt.pause(0.1)
    plt.ioff()
    plt.show()
    
def show_data():
    fig = plt.figure(figsize=(16,8), dpi=100)#获取画布
    ax1 = fig.add_subplot(1,2,1)#创建子图1
    ax2 = fig.add_subplot(1,2,2)#创建子图1
    plt.ion()#开启交互模式
    while 1:
        data = yield
        if(data=='over'):
            break
        ax1.cla() #清除子图的图像
        ax1.grid(color='r', linestyle='--', linewidth=1,alpha=0.3)#添加网格线
        ax1.plot(data[0],data[1], label = 'loss')#绘出折线图
        ax1.legend()#显示标签
        ax2.cla() #清除子图的图像
        ax2.grid(color='r', linestyle='--', linewidth=1,alpha=0.3)#添加网格线
        ax2.plot(data[0],data[2], label = 'recall')
        ax2.plot(data[0],data[3], label = 'precision')
        ax2.legend()
        plt.draw() #交互模式下重新绘制图像
        plt.pause(0.1) #保持显示
    plt.ioff()#关闭交互模式
    plt.show()#显示图像
    
    
from tensorflow.python.framework import graph_util
def Save_model_PB(sess, save_model_name='file_name.pb', nodes=['input_data', 'output_data', 'keep_prob', 'lables']):
    #sess: 当前工作的session
    #save_model_name: 保存模型使用的文件名
    #nodes: 模型固定的节点
    
    #保存模型为pb模型
    output_graph_def = graph_util.convert_variables_to_constants(
        sess=sess,
        input_graph_def=sess.graph_def, #等于:sess.graph_def
        output_node_names=nodes #如果有多个输出节点，以逗号隔开
    )# 模型持久化，将变量值固定,
    with tf.gfile.GFile(save_model_name, "wb") as f: #保存模型
        f.write(output_graph_def.SerializeToString()) #序列化输出
        
def Check_train_result():
    target_class = 0            #目标类别出现的次数
    predict_target_class = 0     #预测目标类别的次数
    predict_target_success = 0    #预测目标类别正确的次数
    pt = 0 #召回率
    pp = 0 #精确率
    #Net_out: 网络输出结果
    #labels: 对应的标签集
    #index: 目标类别的索引,-1为计算过程
    while 1:
        Net_out, labels, index = yield pt,pp
        if index != -1:    #传入非(0,0,*)统计
            for i in range(len(labels)):#统计
                if labels[i][index]==1:
                    target_class+=1
                    if Net_out[i][index]>0.5:
                        predict_target_success+=1
                if Net_out[i][index]>0.5:
                    predict_target_class+=1
        if index == -1:    #传入(0,0,*)返回结果
            if target_class!=0 and predict_target_class!=0:    #防止除以0的情况
                pt = predict_target_success/target_class
                pp = predict_target_success/predict_target_class
            else:
                if target_class==0 and predict_target_class==0:
                    pt = 1
                    pp = 1
                else:
                    pt = 0
                    pp = 0
```

## 主运行文件

```python
import tensorflow as tf
import numpy as np
import random
import cv2
import os
import time

input_data = tf.compat.v1.placeholder('float32', [None,224,224,3], name='input_data')
#input_data = tf.Variable(tf.random.truncated_normal(shape=[1,224,224,3],stddev=0.1))

#网络第一层 
#卷积：输入224×224×3图像，卷积核数量96，卷积核大小11×11×3；步长stride=4；pad=0表示不扩充边缘；
#池化：pool_size = (3, 3), stride = 2, pad = 0
w_conv1 = tf.Variable(tf.random.truncated_normal(shape=[11,11,3,96],stddev=0.1))#第一层卷积核组
b_conv1 = tf.Variable(tf.constant(0.1,shape=[96]))#第一层偏置量
output_data = tf.nn.conv2d(input_data, filter=w_conv1, strides=[1, 4, 4, 1], padding='VALID')#第一层卷积
output_data = tf.nn.relu(output_data + b_conv1)#激活函数
output_data = tf.nn.max_pool2d(output_data, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')#第一层池化

#网络第二层 
#卷积：输入为上一层output_data，尺寸是26×26×96；卷积核数量256，卷积核大小5×5×96；步长stride=1；pad=2；
#池化：pool_size = (3, 3), stride = 2
w_conv2 = tf.Variable(tf.random.truncated_normal(shape=[5,5,96,256],stddev=0.1))#第2层卷积核组
b_conv2 = tf.Variable(tf.constant(0.1,shape=[256]))#第2层偏置量
output_data = tf.nn.conv2d(output_data, filter=w_conv2, strides=[1, 1, 1, 1], padding='SAME')#第2层卷积
output_data = tf.nn.relu(output_data + b_conv2)#激活函数
output_data = tf.nn.max_pool2d(output_data, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')#第2层池化

#网络第三层 
#卷积：输入为上一层output_data，尺寸是12×12×256；卷积核数量384，卷积核大小3×3×256；步长stride=1；pad=1；
w_conv3 = tf.Variable(tf.random.truncated_normal(shape=[3,3,256,384],stddev=0.1))#第3层卷积核组
output_data = tf.nn.conv2d(output_data, filter=w_conv3, strides=[1, 1, 1, 1], padding='SAME')#第3层卷积

#网络第四层 
#卷积：输入为上一层output_data，尺寸是12×12×384；卷积核数量384，卷积核大小3×3×384；步长stride=1；pad=1；
w_conv4 = tf.Variable(tf.random.truncated_normal(shape=[3,3,384,384],stddev=0.1))#第4层卷积核组
output_data = tf.nn.conv2d(output_data, filter=w_conv4, strides=[1, 1, 1, 1], padding='SAME')#第4层卷积

#网络第五层 
#卷积：输入为上一层output_data，尺寸是12×12×384；卷积核数量256，卷积核大小3×3×384；步长stride=1；考虑边界；
#池化：pool_size = (3, 3), stride = 2，考虑边界；
w_conv5 = tf.Variable(tf.random.truncated_normal(shape=[3,3,384,256],stddev=0.1))#第5层卷积核组
b_conv5 = tf.Variable(tf.constant(0.1,shape=[256]))#第5层偏置量
output_data = tf.nn.conv2d(output_data, filter=w_conv5, strides=[1, 1, 1, 1], padding='SAME')#第5层卷积
output_data = tf.nn.relu(output_data + b_conv5)#激活函数
output_data = tf.nn.max_pool2d(output_data, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')#第5层池化

#网络第六层
#全连接：输入为上一层output_data，尺寸是6×6×256；输出尺寸[1024]
#Dropout
w_conv6 = tf.Variable(tf.random.truncated_normal(shape=[6*6*256,1024],stddev=0.1))#第6层权值
b_conv6 = tf.Variable(tf.constant(0.1,shape=[1024]))#第6层偏置量
keep_prob = tf.compat.v1.placeholder("float", name='keep_prob')#用于dropout层，减少过拟合
output_data = tf.nn.relu(tf.matmul(tf.reshape(output_data,[-1,6*6*256]), w_conv6) + b_conv6)#与权值相乘再加上偏置，然后激活
output_data = tf.nn.dropout(output_data, keep_prob)

#网络第七层
#全连接：输入为上一层output_data，尺寸是[1024]；输出尺寸[64]
#Dropout
w_conv7 = tf.Variable(tf.random.truncated_normal(shape=[1024,64],stddev=0.1))#第7层权值
b_conv7 = tf.Variable(tf.constant(0.1,shape=[64]))#第7层偏置量
output_data = tf.nn.relu(tf.matmul(output_data, w_conv7) + b_conv7)#与权值相乘再加上偏置，然后激活
output_data = tf.nn.dropout(output_data, keep_prob)

#网络第八层
#全连接：输入为上一层output_data，尺寸是[64]；输出尺寸[2]
#Dropout
w_conv8 = tf.Variable(tf.random.truncated_normal(shape=[64,2],stddev=0.1))#第6层权值
b_conv8 = tf.Variable(tf.constant(0.1,shape=[2]))#第6层偏置量
output_data = tf.nn.relu(tf.matmul(output_data, w_conv8) + b_conv8)#与权值相乘再加上偏置，然后激活
output_data = tf.nn.dropout(output_data, keep_prob)

#网络第九层
#输出：输入为上一层output_data，尺寸是[2]；输出尺寸[2]
w_conv9 = tf.Variable(tf.random.truncated_normal(shape=[2,2],stddev=0.1))#第9层权值
b_conv9 = tf.Variable(tf.constant(0.1,shape=[2]))#第9层偏置量
output_data = tf.nn.sigmoid(tf.matmul(output_data, w_conv9) + b_conv9)
output_data = tf.nn.softmax(output_data, name='output_data')

from Function_Diy import *
def Train():
    train_images, train_lables, test_images, test_lables = Build_datasets(folder_to_dict(r'C:\Users\jyd\Desktop\data'), [224,224]) 
    lables  = tf.placeholder('float32', [None,2], name='lables')#类别标签
    cross_entropy = tf.reduce_mean(-tf.reduce_sum(lables*tf.log(output_data),axis=1))#交叉熵,tf.clip_by_value(output_data,1e-8,1.0)
    train_step = tf.compat.v1.train.GradientDescentOptimizer(1e-2).minimize(cross_entropy)#训练
    correct_prediction = tf.equal(tf.argmax(output_data,1), tf.argmax(lables,1))#比较预测结果的正确率
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))#比较预测结果的正确率
    
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())#初始化变量
        data_X = list()#训练次数的历史记录
        data_Y = list()#loss的历史记录
        data_Y1 = list()#召回率的历史记录
        data_Y2 = list()#精确率的历史记录
        g = show_data()
        next(g)
        for i in range(1000): #训练次数
            batch = 50  #分批训练,每批的数量
            Accuracy_sum = 0 #每批的正确率之和
            #创建迭代器
            g_che = Check_train_result()
            next(g_che)
            for j in range(len(train_images)//batch):                
                #print('输出矩阵:', sess.run(output_data, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5}))  
                loss = sess.run(cross_entropy, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5})
                print('loss:', loss)  
                Accuracy_sum =sess.run(output_data, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5})
                g_che.send((Accuracy_sum,train_lables[j*batch:(j+1)*batch],0))#统计                
                sess.run(train_step, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5}) #训练
            #print('第',i+1,'次训练的平均正确率:', Accuracy_sum/(len(train_images)//batch)) #打印正确率           
            loss = sess.run(cross_entropy, feed_dict={input_data:train_images, lables:train_lables, keep_prob:0.5})
            if i>20:
                data_X.append(i)
                data_Y.append(loss*100)
                data_Y1.append(g_che.send((0,0,-1))[0])
                data_Y2.append(g_che.send((0,0,-1))[1])
                g.send([data_X,data_Y,data_Y1,data_Y2])
            if(i%500 == 0 and i!=0): #每训练500次保存一次模型
                #Save_model_PB(sess, save_model_name='model_'+str(int(time.time()))+'_'+str(int(loss*10000))+'.pb')#保存为pb格式
                tf.train.Saver().save(sess, './models/model_'+str(int(time.time()))+'_'+str(int(loss*10000))+'.ckpt')
        g.send('over')
        
def Transfer_training(): #迁移训练
    train_images, train_lables, test_images, test_lables = Build_datasets(folder_to_dict(r'C:\Users\jyd\Desktop\data'), [224,224])
    with tf.Session() as sess:
        #加载网络图结构和参数
        saver = tf.compat.v1.train.import_meta_graph('./models/model_1594287957_6687.ckpt.meta')
        saver.restore(sess, './models/model_1594287957_6687.ckpt')
        #通过变量名获取关键变量
        graph = tf.compat.v1.get_default_graph()
        lables = graph.get_tensor_by_name('lables:0')
        output_data = graph.get_tensor_by_name('output_data:0')
        input_data = graph.get_tensor_by_name('input_data:0')
        #训练方式
        cross_entropy = tf.reduce_mean(-tf.reduce_sum(lables*tf.log(output_data),axis=1))#交叉熵,tf.clip_by_value(output_data,1e-8,1.0)
        train_step = tf.compat.v1.train.GradientDescentOptimizer(1e-2).minimize(cross_entropy)#训练
        
        data_X = list()#训练次数的历史记录
        data_Y = list()#loss的历史记录
        data_Y1 = list()#召回率的历史记录
        data_Y2 = list()#精确率的历史记录
        g = show_data()
        next(g)
        for i in range(1000): #训练次数
            batch = 50  #分批训练,每批的数量
            Accuracy_sum = 0 #每批的正确率之和
            #创建迭代器
            g_che = Check_train_result()
            next(g_che)
            for j in range(len(train_images)//batch):                
                #print('输出矩阵:', sess.run(output_data, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5}))  
                loss = sess.run(cross_entropy, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5})
                print('loss:', loss)  
                Accuracy_sum =sess.run(output_data, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5})
                g_che.send((Accuracy_sum,train_lables[j*batch:(j+1)*batch],0))#统计                
                sess.run(train_step, feed_dict={input_data:train_images[j*batch:(j+1)*batch], lables:train_lables[j*batch:(j+1)*batch], keep_prob:0.5}) #训练
            #print('第',i+1,'次训练的平均正确率:', Accuracy_sum/(len(train_images)//batch)) #打印正确率           
            loss = sess.run(cross_entropy, feed_dict={input_data:train_images, lables:train_lables, keep_prob:0.5})
            if i>20:
                data_X.append(i)
                data_Y.append(loss*100)
                data_Y1.append(g_che.send((0,0,-1))[0])
                data_Y2.append(g_che.send((0,0,-1))[1])
                g.send([data_X,data_Y,data_Y1,data_Y2])
            if(i%500 == 0 and i!=0): #每训练500次保存一次模型
                #Save_model_PB(sess, save_model_name='model_'+str(int(time.time()))+'_'+str(int(loss*10000))+'.pb')#保存为pb格式
                tf.train.Saver().save(sess, './models/model_'+str(int(time.time()))+'_'+str(int(loss*10000))+'.ckpt')
        g.send('over')


Transfer_training()
#Predict_by_PB(r'C:\Users\jyd\Desktop\data\train\class2\tianyi (1).jpg')
#camera(r'C:\Users\jyd\Desktop\data\train\class2')
```

